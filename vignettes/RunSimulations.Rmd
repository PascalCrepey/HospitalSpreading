---
title: "Run epidemic simulations along a network using NetworkSpreading"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Run epidemic simulations along a network using NetworkSpreading}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup, include = F, eval = T}
library(HospitalSpreading)
library(microbenchmark)
library(tidyverse)
```

## Simulation model 

`NetworkSpreading` simulates the spread of infection along a network of $n$ interconnected subpopulations $D$. Epidemics are stochastic and simulated under a chain binomial process using the `odin` package. 

Within each subpopulation, individuals are either susceptible ($S$) or infected ($I$). Infected individuals transmit with transmission rate $\beta$ and recover with recovery rate $\alpha$. Subpopulations are interconnected by a transfer matrix $\Omega$ that describes the numbers of individuals that migrate between subpopulations. `NetworkSpreading` assumes that for each subpopulation the total number of entries is equal to the total number of outflows. This assumption ensures that all the $N_{k,t}=S_{k,t}+I_{k,t}$ are constant over time, consequently $N_{k,t} = N_{k}$. When the transfer matrix does not verify this assumption, `NetworkSpreading` assumes that there is an additional population that compensates the unbalanced transfers. We refer to this population as the community. The community is at equilibrium with disease prevalence $p_{com}$. $\omega_{in}$ is the vector of the number of transfers from the community to each subpopulation and $\omega_{out}$ is the vector of the number of transfer from each subpopulation to the community.

At each time step, the epidemic simulation process is divided into two steps:
1. Updating the infection status of transferred individuals 
2. Updating the number of susceptible and infectious individuals per subpopulation

First, `NetworkSpreading` assumes that all individuals have the same probability of being transferred, regardless of their infection status. Transfers occur at the start of each time step and is instantaneous. The number of transferred susceptible individuals from subpopulation $k$ to subpopulation $j$ at time $t+1$ is:

$$
n_{S_k \rightarrow S_{j},t+1} = min \left( S_{k,t}, \Omega_{i,j} \frac{S_{k,t}}{N_{k}} \right)
$$

Since there are only two compartments per subpopulation, the number of transferred infected individuals from subpopulation $k$ to subpopulation $j$ at time $t+1$ is directly given by:
$$
n_{I_k \rightarrow I_{j},t+1} = \Omega_{i,j} - n_{S_k \rightarrow S_{j},t+1}
$$

The new number of susceptible and infected individuals at the beginning of time step $t+1$ is:
$$
S_{k,t+1\:start} = S_{k,t} + \sum_j n_{S_j \rightarrow S_{j},t+1} - n_{S_k \rightarrow S_{j},t+1} \\
I_{k,t+1\:start} = I_{k,t} + \sum_j n_{I_j \rightarrow I_{j},t+1} - n_{I_k \rightarrow I_{j},t+1}
$$

Then, the transmission process is simulated at time $t+1$ using the updated prevalence following individual transfers. The number of newly infected individuals per subpopulation is drawn from a binomial distribution as follows:

$$
n_{S_k \rightarrow I_k, t+1} \sim B \left( S_{k,t+1\:start} , 1-exp(-\beta \:S_{k,t+1\:start} / N_k ) \right)
$$
The number of new recovered individuals at time $t+1$ is drawn from the following binomial distribution:
$$
n_{I_k \rightarrow S_k, t+1} \sim B \left( I_{k,t+1\:start} , 1-exp(-\alpha) \right)
$$
Finally, the number of susceptible and infected individuals is updated:

$$
S_{k,t+1} = S_{k,t+1 \: start} + n_{I_k \rightarrow S_k, t+1} - n_{S_k \rightarrow I_k, t+1} \\
I_{k,t+1} = I_{k,t+1 \: start} + n_{S_k \rightarrow I_k, t+1} - n_{I_k \rightarrow S_k, t+1}
$$

## Parameters

Here we describe and define each of the parameters needed to run the simulation model.

```{r call_parameters}
time_step = 1                             # time step
tspan_max = 100                           # final time step
beta = 0.5                                # transmission rate
alpha = 0.1                               # recovery rate
size_subpop = c(112, 144, 131, 119, 120)  # vector of the sizes of the subpopulations
I_initial_time = c(3, 0, 0, 0, 0)         # no. infected individuals at t=0
community_prev = 0.1                      # disease prevalence in the community  
```

The ***size_subpop*** vector contains the size of each subpopulation and the vector ***I_initial_time*** contains the initial number of infected individuals in each subpopulation. In our example, there are 0 infected individual at the start of the epidemic except in subpopulation 1 where 3 individuals are infected.

It is also possible to simply give the total number of infected individuals at time $t=0$ across the network and choose a randomisation procedure to allocate the individuals to the different subpopulations. Several options are available:

- ***uniform***: the infected individuals are uniformly allocated to the subpopulations, 
- ***largest_pop***: the probability of allocation of the infected individuals is proportional to subpopulation size,
- ***most_connected_pop***: the probability of allocation of the infected individuals is proportional to the total number of individuals that get in and out of the subpopulation.

```{r example_randomisation, eval=F}
I_initial_time = 3                    # no. infected individuals at t=0
initial_state_rando_proc = "uniform"  # randomisation procedure of the infected individuals at t=0
```

## Transfer matrix

We define a matrix of transfers between subpopulations. This matrix corresponds to the number of individuals that migration from subpopulation $i$ (in rows) to subpopulation $j$ (in columns)  at each time step $t$. In this analysis, the matrix transfer is randomly chosen.

```{r transfer_matrix, eval=T}
npop = length(size_subpop)
trans_mat = make_fake_matrix(nmetapop = npop, scale = 10)
```

Alternatively, one can use the `HospitalNetwork` package to generate a random network. In this case, `HospitalNetwork` will provide the transfer matrix and the vector of subpopulation sizes.

```{r random_hospitalnetwork, eval=F, message=F}
library(HospitalNetwork)

# Create a dummy database of transfers between 5 hospitals with a total of 300 subjects  
dummy_data = create_fake_subjectDB(n_subjects = 300, n_facilities = 5)
dummy_data_checked = checkBase(dummy_data)

# Build and extract the transfer matrix 
dummy_network = hospinet_from_subject_database(dummy_data_checked)
transfer_matrix = dummy_network$matrix

# Number of individuals per hospital, i.e. subpopulation sizes
size_subpop = dummy_network$subjectsPerHosp$subjects
```


## Model initialisation
We initialise the SIS model using the predefined parameters.

```{r init_models, echo=TRUE, message=FALSE, eval=T}
odin_model <- initialize_sis(
  beta = beta,
  alpha = alpha,
  size_subpop = size_subpop,
  transfer_matrix = trans_mat,
  I_initial_time = I_initial_time,
  community_prev = community_prev,
  initial_state_rando_proc = "none"
  )
```

## Model execution
We then run the model using these parameters.

```{r run_model, echo=TRUE, eval=T}
odin_result <- run_simulation(odin_model, tspan_max, time_step)
```

By default, the function `run_simulation` simulates one epidemic. More epidemics can be simulated at the same time by specifying the number of replicates as follows:  
```{r run_model_multiple, eval=F,echo=TRUE, message=FALSE} 
odin_result <- run_simulation(odin_model, tspan_max, time_step, 20)
```

## Model output
The output of the simulation model is a list of 5 elements:

- `prevalence`: an array of the total number of infected individuals at time t (row) in every subpopulation (column). Here, we simulated only one epidemic, hence the output is a matrix. In the case of multiple simulated epidemics, the array has 3 dimensions, the third dimension corresponding to the simulations. 

```{r model_prevalence, echo = T}
head(odin_result$prevalence)
```

- `incidence`: an array of the number of new infected individuals at time t (row) in every subpopulation (column). Here, we simulated only one epidemic, hence the output is a matrix. In the case of multiple simulated epidemics, the array has 3 dimensions, the third dimension corresponding to the simulations. 

```{r model_incidence, echo = T}
head(odin_result$incidence)
```

- `transfers_I`: a list of arrays. Each array contains the number of infected individuals transferred from one subpopulation (row) to another subpopulation (column) at each timestep (3rd dimension). The list contains as many arrays as the number of simulations.
```{r model_transfers_I, echo = T}
odin_result$transfers_I[[1]][,,1:2]
```

- `transfers_tot`: input matrix of the total number of transfers between subpopulations
```{r model_transfers_tot, echo = T}
odin_result$transfers_tot
```

- `subpop_size`: input vector of the subpopulation sizes
```{r model_subpop_size, echo = T}
odin_result$subpop_size
```

## Time performance
We use the package `microbenchmark` to evaluate the running time of NetworkSpreading over 100 simulations.

```{r runtime_tests, echo = T, eval=T}
print(benchmark_odin(odin_model, times = 0:(tspan_max*time_step), nRun = 100))
```

## Across multiple simulations
To compare the model outputs while controlling for the stochasticity, we conduct multiple simulations of each with the same parameters. We compare over a simulation in a single hospital with no migration. 

We also conduct an equivalent deterministic simulation use `deSolve`.

```{r init_multi_models, message = F, eval=T, fig.width = 7}
Nsims = 100
trans_mat_null = matrix(0, nrow = npop, ncol = npop)

# Initialise model
odin_model <- initialize_sis(
  beta = beta/time_step,
  alpha = alpha/time_step,
  size_subpop = size_subpop,
  transfer_matrix = trans_mat,
  I_initial_time = I_initial_time,
  community_prev = community_prev,
  initial_state_rando_proc = "none"
  )

# Run model for 100 simulations
odin_runs <- odin_model$run(0:(tspan_max*time_step), replicate = Nsims)

# Retrieve dynamics of S and I compartments 
for(i in 1:Nsims){
  
  odin_multi_piece <- odin_runs[,,i] %>%
    as_tibble %>%
    select(step, starts_with("S["), starts_with("I[")) %>%
    rename_all(~gsub("\\[", "_", .x)) %>%
    rename_all(~gsub("\\]", "", .x)) %>%
    rename(times = step) %>%
    pivot_longer(-times, names_sep = "_", names_to = c("state", "metapop")) %>%
    mutate(metapop = as.numeric(metapop), sim = i)

  if(i == 1){
    odin_multi <- odin_multi_piece
  } else {
    odin_multi <- rbind(odin_multi, odin_multi_piece)
  }
}

# Plot results
odin_multi %>%
  mutate(times = times/time_step) %>%
  group_by(times, metapop, state) %>%
  summarise(mean = mean(value)
            , lo = max(value)
            , hi = min(value)) %>%
  filter(times < 30, metapop == 1) %>%
  ggplot(.) +
  geom_line(aes(x = times, y = mean, linetype = "mean")) +
  geom_line(aes(x = times, y = lo, linetype = "range")) +
  geom_line(aes(x = times, y = hi, linetype = "range")) +
  facet_grid(metapop~state)

```

## Unit tests

Ideas of unit tests that could be implemented:

- Subpopulation sizes $N_i$ are constant over time
- The total number of transfers $\Omega$ is equal to the input transfer matrix and constant over time
- Compartments $S_i$ and $I_i$ are always positive or null 

